{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\first\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Trains a simple convnet on the MNIST dataset\n",
    "Using CNN with maxpooling.\n",
    "\n",
    "\"\"\"\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, Input,Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28)\n",
      "y_train shape: (60000,)\n",
      "x_test shape: (10000, 28, 28)\n",
      "y_test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "y_train shape: (60000,)\n",
      "x_test shape: (10000, 28, 28, 1)\n",
      "y_test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# check banked image data format\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train dtype: float32\n",
      "y_train dtype: uint8\n",
      "x_test dtype: float32\n",
      "y_test dtype: uint8\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# transform data type\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train dtype:', x_train.dtype)\n",
    "print('y_train dtype:', y_train.dtype)\n",
    "print('x_test dtype:', x_test.dtype)\n",
    "print('y_test dtype:', y_test.dtype)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "y_train shape: (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv2D_layer_1 (Conv2D)      (None, 24, 24, 16)        416       \n",
      "_________________________________________________________________\n",
      "MaxP_layer_1 (MaxPooling2D)  (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "Conv2D_layer_2 (Conv2D)      (None, 10, 10, 32)        4640      \n",
      "_________________________________________________________________\n",
      "MaxP_layer_2 (MaxPooling2D)  (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "Drop_layer_1 (Dropout)       (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "Dense_layer_1 (Dense)        (None, 64)                51264     \n",
      "_________________________________________________________________\n",
      "Dense_layer_2 (Dense)        (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "Drop_layer_2 (Dropout)       (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output_layer_1 (Dense)       (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 65,930\n",
      "Trainable params: 65,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# build CNN maxpool model using Keras sequential model API\n",
    "model_1 = Sequential()\n",
    "\n",
    "# type your code of model here\n",
    "model_1.add(Conv2D(16, (5,5), activation=\"relu\", input_shape=input_shape, name='Conv2D_layer_1'))\n",
    "\n",
    "model_1.add(MaxPooling2D(pool_size=(2,2), name='MaxP_layer_1'))\n",
    "\n",
    "model_1.add(Conv2D(32, (3,3), activation=\"relu\", name='Conv2D_layer_2'))\n",
    "\n",
    "model_1.add(MaxPooling2D(pool_size=(2,2), name='MaxP_layer_2'))\n",
    "\n",
    "model_1.add(Dropout(0.25, name='Drop_layer_1'))\n",
    "\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(64, activation=\"relu\", name='Dense_layer_1'))\n",
    "model_1.add(Dense(128, activation=\"relu\", name='Dense_layer_2'))\n",
    "model_1.add(Dropout(0.5, name='Drop_layer_2'))\n",
    "model_1.add(Dense(10, activation=\"softmax\", name='output_layer_1'))\n",
    "\n",
    "model_1.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 18s 308us/step - loss: 0.3419 - acc: 0.8909 - val_loss: 0.0606 - val_acc: 0.9814\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 16s 260us/step - loss: 0.0950 - acc: 0.9730 - val_loss: 0.0390 - val_acc: 0.9870\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 16s 259us/step - loss: 0.0740 - acc: 0.9791 - val_loss: 0.0355 - val_acc: 0.9884\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 16s 263us/step - loss: 0.0589 - acc: 0.9827 - val_loss: 0.0315 - val_acc: 0.9892\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 16s 262us/step - loss: 0.0540 - acc: 0.9844 - val_loss: 0.0275 - val_acc: 0.9907\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 16s 260us/step - loss: 0.0471 - acc: 0.9866 - val_loss: 0.0305 - val_acc: 0.9907\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 16s 259us/step - loss: 0.0415 - acc: 0.9884 - val_loss: 0.0297 - val_acc: 0.9905\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 16s 260us/step - loss: 0.0398 - acc: 0.9884 - val_loss: 0.0281 - val_acc: 0.9918\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 16s 261us/step - loss: 0.0367 - acc: 0.9896 - val_loss: 0.0240 - val_acc: 0.9923\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 16s 259us/step - loss: 0.0351 - acc: 0.9896 - val_loss: 0.0245 - val_acc: 0.9934\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 16s 260us/step - loss: 0.0330 - acc: 0.9902 - val_loss: 0.0246 - val_acc: 0.9927\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 16s 260us/step - loss: 0.0307 - acc: 0.9910 - val_loss: 0.0223 - val_acc: 0.9929\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 16s 259us/step - loss: 0.0279 - acc: 0.9916 - val_loss: 0.0240 - val_acc: 0.9925\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 16s 260us/step - loss: 0.0260 - acc: 0.9919 - val_loss: 0.0256 - val_acc: 0.9917\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 16s 260us/step - loss: 0.0264 - acc: 0.9922 - val_loss: 0.0214 - val_acc: 0.9934\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 16s 260us/step - loss: 0.0247 - acc: 0.9924 - val_loss: 0.0246 - val_acc: 0.9928\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 16s 266us/step - loss: 0.0246 - acc: 0.9930 - val_loss: 0.0225 - val_acc: 0.9932\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 16s 260us/step - loss: 0.0230 - acc: 0.9930 - val_loss: 0.0212 - val_acc: 0.9938\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 16s 260us/step - loss: 0.0228 - acc: 0.9934 - val_loss: 0.0221 - val_acc: 0.9934\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 16s 261us/step - loss: 0.0221 - acc: 0.9933 - val_loss: 0.0222 - val_acc: 0.9931\n"
     ]
    }
   ],
   "source": [
    "# train mode using mini-batch\n",
    "train_history = model_1.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.312755865859985\n",
      "Train accuracy: 0.10698333333333333\n"
     ]
    }
   ],
   "source": [
    "# test the trained model using training data\n",
    "score = model_1.evaluate(x_train, y_train, verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.313011138153076\n",
      "Test accuracy: 0.1066\n"
     ]
    }
   ],
   "source": [
    "# test the trained model using testing data\n",
    "score = model_1.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
